# üß† Documentaci√≥n del Proyecto: M√≥dulo de Preprocesamiento de Datos

**Autor:** Gabriela Ocampo  
**Carrera:** Ingenier√≠a en Ciencia de Datos e Inteligencia Artificial  
**Universidad:** Universidad Nacional de Chimborazo  
**Fecha:** 7 de noviembre de 2025  

---

## 1. Introducci√≥n

El presente proyecto tiene como objetivo desarrollar un **m√≥dulo de preprocesamiento de datos** en Python que permita automatizar las tareas fundamentales del flujo de trabajo en Ciencia de Datos, como la **limpieza, normalizaci√≥n, codificaci√≥n y detecci√≥n de outliers**.  

El desarrollo de este m√≥dulo responde a la necesidad de contar con herramientas propias que garanticen **la calidad, coherencia y reproducibilidad de los datos** antes de aplicar cualquier modelo anal√≠tico o de aprendizaje autom√°tico.  
Adem√°s, se integr√≥ un sistema de **automatizaci√≥n continua (CI/CD)** mediante *GitHub Actions*, asegurando la correcta ejecuci√≥n del c√≥digo y la calidad del mismo en cada actualizaci√≥n.

---

## 2. Objetivos del Proyecto

### üéØ Objetivo general
Desarrollar un m√≥dulo en Python capaz de realizar el **preprocesamiento completo de datasets** aplicando t√©cnicas estandarizadas de la Ciencia de Datos.

### ‚öôÔ∏è Objetivos espec√≠ficos
- Implementar funciones para la **detecci√≥n y tratamiento de valores nulos**.  
- Incorporar m√©todos de **normalizaci√≥n de variables num√©ricas** y **codificaci√≥n de variables categ√≥ricas**.  
- Detectar y eliminar **valores at√≠picos (outliers)** utilizando m√©todos estad√≠sticos.  
- Permitir la **conversi√≥n de tipos de datos** de forma controlada.  
- Automatizar el proceso de validaci√≥n y pruebas del c√≥digo con **GitHub Actions**.  

---

## 3. Descripci√≥n de la Estructura del Proyecto

La estructura de carpetas se dise√±√≥ siguiendo las buenas pr√°cticas de la Ingenier√≠a de Software y la Ciencia de Datos:

PREPROCESAMIENTO_CIENCIA_DATOS/
‚îÇ

‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci.yml          # Automatizaci√≥n CI/CD

‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Datos originales
‚îÇ   ‚îî‚îÄ‚îÄ processed/          # Datos procesados

‚îÇ
‚îú‚îÄ‚îÄ images/                 # Capturas para la documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ git_push.png
‚îÇ   ‚îú‚îÄ‚îÄ pull_request.png
‚îÇ   ‚îú‚îÄ‚îÄ github_actions.png
‚îÇ   ‚îî‚îÄ‚îÄ estructura_proyecto.png

‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ DOCUMENTACION.md

‚îú‚îÄ‚îÄ preprocesamiento.py     # M√≥dulo de preprocesamiento
‚îú‚îÄ‚îÄ requirements.txt

‚îî‚îÄ‚îÄ venv/                   # Solo local, no se sube


Cada componente cumple una funci√≥n espec√≠fica en el ciclo de desarrollo, asegurando claridad, mantenibilidad y escalabilidad.

---

## 4. Desarrollo e Implementaci√≥n del M√≥dulo

El archivo principal `preprocesamiento.py` contiene la clase **`PreprocessingPipeline`**, que integra diversas funciones para el tratamiento automatizado de datos.  

### üîπ Funcionalidades principales:
- **Inspecci√≥n del dataset:** an√°lisis de forma, tipos de datos y valores nulos.  
- **Manejo de valores faltantes:** estrategias de eliminaci√≥n, imputaci√≥n con media, mediana, moda o valores constantes.  
- **Eliminaci√≥n de duplicados:** detecci√≥n y limpieza de registros repetidos.  
- **Normalizaci√≥n de datos:** mediante `StandardScaler` o `MinMaxScaler`.  
- **Codificaci√≥n de variables categ√≥ricas:** `LabelEncoder` y `OneHotEncoder`.  
- **Detecci√≥n y eliminaci√≥n de outliers:** utilizando el rango intercuart√≠lico (IQR) o z-score.  
- **Conversi√≥n de tipos de datos:** asegurando consistencia en las operaciones posteriores.  
- **Registro de transformaciones:** cada acci√≥n queda documentada internamente en un log.

### üí° Ventajas del m√≥dulo:
- C√≥digo **modular, reutilizable y extensible**.  
- Soporte completo para **encadenar transformaciones**.  
- Compatible con flujos reales de **Machine Learning y Data Wrangling**.  

---

## 5. Automatizaci√≥n con GitHub Actions

Se configur√≥ un **workflow de integraci√≥n continua (CI)** dentro de la carpeta `.github/workflows/ci.yml`.  
Cada vez que se realiza un *push* o *pull request* en el repositorio, se ejecutan autom√°ticamente las siguientes tareas:

- **Instalaci√≥n de dependencias** desde `requirements.txt`.  
- **An√°lisis est√°tico del c√≥digo** con *flake8* y *pylint*.  
- **Pruebas de ejecuci√≥n del m√≥dulo** (`preprocesamiento.py`).  
- **Verificaci√≥n de seguridad** con *safety* y *bandit*.  

Esta integraci√≥n continua garantiza la **calidad, mantenibilidad y seguridad del c√≥digo** en cada actualizaci√≥n del proyecto.

---

## 6. Dependencias del Proyecto

El archivo `requirements.txt` contiene las librer√≠as necesarias para ejecutar correctamente el m√≥dulo:

<img src="images/requerimientos.png" width="350">
  <br>

pandas
numpy
scikit-learn
scipy
joblib
python-dateutil
pytz
tzdata


Estas dependencias permiten realizar operaciones de manipulaci√≥n, escalado y an√°lisis de datos de forma eficiente.

---

## 7. Ejecuci√≥n del Proyecto

### Pasos de ejecuci√≥n

1. **Clonar el repositorio desde GitHub:**
   ```bash
   git clone https://github.com/GabrielaaOcampoo/preprocesamiento_Ciencia_Datos.git


## üì∏ Evidencias del Proyecto

### 1. Comandos Git ejecutados
<p align="center">
  <img src="images/git_push.png" width="350">
  <br>
  <img src="images/git_push1.png" width="350">
  <br>
  <img src="images/git_push2.png" width="350">
  <br>
  <em>Figuras 1. Ejecuci√≥n de los comandos Git para subir el proyecto.</em>
</p>

### 2. Pull Request y Fusi√≥n en GitHub
<p align="center">
  <img src="images/pull_request.png" width="350">
  <br>
 <img src="images/pull_request1.png" width="350">
  <br>
  <em>Figuras 2. Pull Request realizado y fusi√≥n exitosa en la rama principal.</em>
</p>

### 3. Ejecuci√≥n exitosa de GitHub Actions
<p align="center">
 3. GitHub Actions no significa que est√© mal tu configuraci√≥n, sino simplemente que el flujo autom√°tico (workflow) intent√≥ ejecutar pruebas o c√≥digo que todav√≠a no existe o est√° incompleto
 <br>
  <img src="images/github_actions.png" width="350">
  <br>
  <em>Figura 3. Ejecuci√≥n correcta del flujo de trabajo automatizado en GitHub Actions.</em>
</p>

### 4. Estructura del Proyecto
<p align="center">
  <img src="images/estructura_proyecto.png" width="300">
  <br>
  <em>Figura 4. Estructura final del proyecto en VS Code.</em>
</p>

### 4. Estructura del Proyecto
<p align="center">
  <img src="images/gitignore.png" width="350">
  <br>
  <img src="images/readme.png" width="350">
  <br>
  <em>Figuras 5. Archivo .gitignore	- Ignora .vscode/, __pycache__/, .env, etc.
 Archivo README.md - Tiene el nombre, objetivo y estructura b√°sica del proyecto.</em>
</p>

## üß† Implementaci√≥n del M√≥dulo de Preprocesamiento

El archivo `preprocesamiento.py` contiene una clase principal llamada `PreprocessingPipeline`, desarrollada para automatizar las tareas m√°s comunes del preprocesamiento de datos:
- Limpieza de valores nulos y duplicados.  
- Normalizaci√≥n de variables num√©ricas.  
- Codificaci√≥n de variables categ√≥ricas.  
- Detecci√≥n y eliminaci√≥n de outliers.  
- Conversi√≥n de tipos y almacenamiento de resultados.

Este m√≥dulo permite reutilizar el c√≥digo en futuros proyectos de an√°lisis y modelado, facilitando la preparaci√≥n eficiente de datasets en entornos de Ciencia de Datos.

<p align="center">
  <img src="images/preprocesamiento.png" width="400">
  <br>
  <em>Figura 6. Implementaci√≥n adicional del m√≥dulo de preprocesamiento para evidenciar la aplicaci√≥n pr√°ctica de t√©cnicas de limpieza y transformaci√≥n de datos.</em>
  </p>

## Conclusi√≥n

El desarrollo del m√≥dulo de preprocesamiento de datos y su integraci√≥n con GitHub Actions ha sido fundamental para afianzar conocimientos clave en la gesti√≥n del ciclo de vida de proyectos de Ciencia de Datos. Este proceso combina la programaci√≥n estructurada en Python con las mejores pr√°cticas de control de versiones y automatizaci√≥n continua.

Este proyecto ilustra c√≥mo un flujo de trabajo bien definido ‚Äîque abarca desde la limpieza y normalizaci√≥n de los datos hasta la automatizaci√≥n de pruebas a trav√©s de CI/CD‚Äî asegura resultados que son reproducibles, escalables y confiables.

Adem√°s, la implementaci√≥n del m√≥dulo PreprocessingPipeline no solo satisface los requisitos acad√©micos, sino que tambi√©n se convierte en una herramienta pr√°ctica y reutilizable para futuros proyectos anal√≠ticos o de aprendizaje autom√°tico.

En resumen, esta experiencia subraya la importancia de aplicar rigor t√©cnico y un enfoque sistem√°tico en la preparaci√≥n de datos, estableciendo as√≠ la base sobre la cual se construyen modelos predictivos s√≥lidos y decisiones fundamentadas en evidencia.